{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI 參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# 載入環境變數\n",
    "load_dotenv()\n",
    "\n",
    "# 設定呼叫 Azure OpenAI Service API 所需連線資訊\n",
    "azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key=os.getenv(\"AZURE_OPENAI_API_KEY\") \n",
    "api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# 最簡之 API 呼叫\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint=azure_endpoint, \n",
    "  api_key=api_key,  \n",
    "  api_version=api_version\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temperature\n",
    "\n",
    "預設值 1\n",
    "\n",
    "決定採樣時的溫度 (sampling temperature)，參數值介於 0 與 2 之間。 數值越高意味著模型產生的文字內容越多樣化，對於更需要產生具備創意之文案的相關應用，可以嘗試使用 0.9，對於具有明確答案應用情境，建議嘗試使用 0 ( 使用 argmax 函數來採樣)。\n",
    "\n",
    "temperature 參數或 top_p 參數有著類似效果，但不要同時調整這兩個參數以避免無法確認內容產出的變化是因為哪一個參數調整所造成的。本範例嘗試使用 gpt-35-turbo 與 gpt-4 開始支援的 ChatCompletion API 來進行自動完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 透過環境變數取得所使用的模型部署名稱\n",
    "model = os.getenv('CHAT_DEPLOYMENT_NAME')\n",
    "\n",
    "def call_openai(num_times, prompt, temperature):\n",
    "    for i in range(num_times):       \n",
    "        response = client.chat.completions.create(\n",
    "            model= model,\n",
    "            messages = [{'role': 'user', 'content':prompt}],\n",
    "            max_tokens=60,\n",
    "            temperature = temperature,\n",
    "        )\n",
    "        print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳的寵物因人而異，取決於你的生活方式和偏好。\n",
      "最佳的寵物取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，視個人需求和喜好而定。\n",
      "最佳的寵物因人而異，取決於個人需求和生活方式。\n",
      "因人而異，每個人心目中的最佳寵物都不同。\n",
      "最佳的寵物因人而異，依喜好和生活方式而定。\n",
      "最適合你的生活方式和需求的寵物就是最佳的寵物。\n",
      "最佳的寵物因人而異，主要看個人的喜好和生活方式。\n",
      "最佳的寵物取決於主人的生活方式和需求。\n",
      "因人而異，視個人喜好與生活方式決定。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', temperature = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top_p\n",
    "\n",
    "預設值 1\n",
    "\n",
    "控制採樣溫度 (sampling temperature) 之外的另一種控制產生內容多樣性的參數，temperature 參數控制產生的內容之隨機性，而 top_p  則決定可供選擇的 Token 範圍有多大，top_p 參數使用 nucleus sampling 採樣方式，一般而言候選的 Token 機率依據高低會以長尾的方式分布，top_p 決定了只有多少百分比之候選 Token 應該被納入考慮，例如 top_p 參數設為 0.1 代表只有前 10% 的候選 Token 有機會被隨機選用。對於 temperature 與 top_p 參數背後所代表的意義可以參考 https://towardsdatascience.com/how-to-sample-from-language-models-682bceb97277\n",
    "\n",
    "temperature 參數或 top_p 參數有著類似效果，但不要同時調整這兩個參數以避免無法確認內容產出的變化是因為哪一個參數調整所造成的。本範例嘗試使用 gpt-35-turbo 與 gpt-4 開始支援的 ChatCompletion API 來進行自動完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, top_p):\n",
    "    for i in range(num_times):       \n",
    "        response = client.chat.completions.create(\n",
    "            model= model, \n",
    "            messages = [{'role': 'user', 'content':prompt}],\n",
    "            max_tokens=60,        \n",
    "            top_p = top_p\n",
    "        )\n",
    "        print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳的寵物因人而異，但通常是與主人性格和生活方式最契合的動物。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活習慣。\n",
      "最佳的寵物因人而異，依個人喜好決定。\n",
      "最適合你的生活方式與需求的寵物。\n",
      "最佳的寵物取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，但某些人喜愛忠誠的狗。\n",
      "最佳的寵物取決於個人喜好與生活方式。\n",
      "最佳的寵物因人而異，視個人喜好和生活方式而定。\n",
      "A: 最佳的寵物因人而異，取決於個人喜好和生活方式。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', top_p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n"
     ]
    }
   ],
   "source": [
    "call_openai(10, '用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:', top_p = 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n\n",
    "\n",
    "預設值 1\n",
    "\n",
    "為每個提示 (prompt) 產生多少個自動完成的回應內容。\n",
    "\n",
    "請注意：由於此參數會生成多個回應內容，因此它會快速消耗 Token 配額。 請謹慎使用並確認有設定妥 max_tokens 參數與停止產生內容的 stop 字串。本範例嘗試使用 gpt-35-turbo 與 gpt-4 開始支援的 ChatCompletion API 來進行自動完成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n",
      "最佳的寵物取決於個人喜好和生活方式。\n",
      "最佳的寵物因人而異，取決於個人喜好和生活方式。\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model = model,  \n",
    "  messages = [ \n",
    "    {'role': 'user', 'content': \"用正體中文一句話精簡回覆\\nQ:最佳的寵物是什麼?\\nA:\"      \n",
    "    }\n",
    "  ],\n",
    "  n=3, # 產生三個自動完成的回覆\n",
    "  temperature=0.6,\n",
    "  max_tokens=200\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "print(response.choices[1].message.content)\n",
    "print(response.choices[2].message.content)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logprobs\n",
    "\n",
    "預設值 null\n",
    "\n",
    "logprobs 會列出最有可能的 Token 以及其他候選之 Token 的機率。 例如如果 logprobs 設為 5，則 API 呼叫後將會回傳 5 個最可能 Token 的清單。 API 仍將傳會機率最高的 Token。 logprobs 的最大值為 5。如果您需要更高的參數值，請聯繫微軟技術支援中心以便讓微軟了解您的需求。由於 OpenAI 許多新模型已經不再支援 logprobs 參數，本範例使用與過去 GPT-3 相容性最高的 gpt-35-turbo-instruct 模型展示如何使用 logprobs 參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best pet name is subjective and can vary depending\n",
      "Logprobs(text_offset=[31, 35, 40, 44, 49, 52, 63, 67, 71, 76], token_logprobs=[-0.8211408, -0.0008969317, -0.0008701292, -0.001026497, -0.03300924, -0.050233137, -0.01647465, -0.77131057, -0.02149361, -0.5570419], tokens=[' The', ' best', ' pet', ' name', ' is', ' subjective', ' and', ' can', ' vary', ' depending'], top_logprobs=[{' The': -0.8211408, 'The': -1.3426118}, {' best': -0.0008969317, ' answer': -7.8318944}, {' pet': -0.0008701292, ' name': -7.120272}, {' name': -0.001026497, ' names': -7.0283875}, {' is': -0.03300924, ' varies': -4.5251756}, {' subjective': -0.050233137, ' a': -3.6106942}, {' and': -0.01647465, ',': -4.3942823}, {' can': -0.77131057, ' varies': -1.148298}, {' vary': -0.02149361, ' differ': -4.322843}, {' depending': -0.5570419, ' based': -1.4554832}])\n",
      "[{' The': -0.8211408, 'The': -1.3426118}, {' best': -0.0008969317, ' answer': -7.8318944}, {' pet': -0.0008701292, ' name': -7.120272}, {' name': -0.001026497, ' names': -7.0283875}, {' is': -0.03300924, ' varies': -4.5251756}, {' subjective': -0.050233137, ' a': -3.6106942}, {' and': -0.01647465, ',': -4.3942823}, {' can': -0.77131057, ' varies': -1.148298}, {' vary': -0.02149361, ' differ': -4.322843}, {' depending': -0.5570419, ' based': -1.4554832}]\n"
     ]
    }
   ],
   "source": [
    "# 透過環境變數取得所使用的模型部署名稱\n",
    "model = os.getenv('COMPLETIONS_DEPLOYMENT_NAME')\n",
    "\n",
    "response  = client.completions.create(\n",
    "            model=model,\n",
    "            prompt='Q:What is the best pet name?\\nA:',\n",
    "            max_tokens=10,\n",
    "            temperature = 0,\n",
    "            logprobs=2,\n",
    "            stop='\\n'\n",
    "        )\n",
    "# 顯示完整回應內容\n",
    "print(response.choices[0].text)\n",
    "# 顯示 logprobs 所有內容\n",
    "print(response.choices[0].logprobs)\n",
    "# 顯示機率最高的前兩個英文字清單\n",
    "print(response.choices[0].logprobs.top_logprobs)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_tokens\n",
    "\n",
    "預設值 無上限\n",
    "\n",
    "生成內容允許之 token 數上限。此外包含提示 (prompt) 耗用的 token 數與生成內容耗用的 token 之數總和不能超過所選用模型允許之 token 數上限。\n",
    "\n",
    "# stop\n",
    "\n",
    "預設值 null\n",
    "\n",
    "讓自動完成 API 停止產生語句的特定字串，只要遇到此參數指定的字串就會結束內容生成，最多可以設定 4 組 Stop 字串。\n",
    "\n",
    "# presence_penalty\n",
    "\n",
    "預設值 0\n",
    "\n",
    "參數值可介於 -2.0 和 2.0 之間的數字，數值大於 0 的設定值會開始在取樣時懲罰使用過的 token，也就是增加產生新的語句或新的主題之可能性。\n",
    "\n",
    "# frequency_penalty\n",
    "\n",
    "預設值 0\n",
    "\n",
    "參數值可介於 -2.0 和 2.0 之間的數字。數值大於 0 的設定值會開始在產生的文本中已經出現過的詞彙時在取樣時進行懲罰，進而降低模型產生重複詞彙的可能性。presence_penalty 參數與 frequency_penalty 參數之間的區別很微妙，frequency_penalty 可以視為控制單詞重複的方法，而將 presence_penalty 視為避免模型產生重複的主題。\n",
    "\n",
    "# stream\n",
    "\n",
    "預設值 false\n",
    "\n",
    "OpenAI 自動完成 API 預設是整個生成內容完成後才會回傳結果，如果您生成內容的時間很長，用戶等待時間就會很久。當 stream 參數設為 true 時，可以在內容生成時以串流 (stream) 方式將目前生成的最新字句立即傳送回來，相關範例可參閱 [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_stream_completions.ipynb)\n",
    "\n",
    "\n",
    "# best_of\n",
    "\n",
    "預設值 1\n",
    "\n",
    "依據參數值在伺服器端生成多個自動完成的結果，將 \"最佳\" 的結果回傳，當設定值大於 1 的就無法啟用與使用 streame 功能。若 best_of 參數與 n 參數一起使用時，best_of 決定了有多少個候選生成出來的內容數量，n 則決定了最終回傳幾個生成的內容數量，也因 best_of 參數值必須大於 n 的參數值。 此外 gpt-35-turbo 與 gpt-4 模型已經不再支援 best_of 參數。\n",
    "請注意：由於此參數會生成多個回應內容，因此它會快速消耗 Token 配額。 請謹慎使用並確認有設定妥 max_tokens 參數與停止產生內容的 stop 字串。\n",
    "\n",
    "\n",
    "# logit_bias\n",
    "\n",
    "預設值 null\n",
    "\n",
    "修改特定 tokens 出現在自動生成 (completion) 產生之文句中的可能性。OpenAI GPT 模型每個字代表之絕對為一之 token ID 是多少? 則可利用　https://platform.openai.com/tokenizer　查詢查詢得知\n",
    "\n",
    "利用 JSON 格式來設定特定 token ID 與配套之 -100 之間 100 數值，數值 -100 表示絕對不會產生出該 token ID 所代表的字。\n",
    "\n",
    "例如您可以設定參數值 {\"16108\": -100} 來避免 token ID 為 50256 所代表的字 \"Apple\" 被模型產生出來。\n",
    "\n",
    "參考資料 : [OpenAI API Reference](https://platform.openai.com/docs/api-reference/completions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
